[["index.html", "STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 10 1.1 Build recommender systems and make predictions 1.2 Evaluate recommender systems", " STATS5099 Data Mining and Machine Learning 1 Welcome to DMML Lab 10 In week 10, we studied recommendation systems. In today's lab, we will look at how to build a user-based collaborative filtering system, an item-based collaborative filtering system, and UV decomposition-based system. In addition, we will evaluate these three recommendation systems for both rating predictions and top-\\(N\\) recommendations. 1.1 Build recommender systems and make predictions We will use the R package recommenderlab to build the collaborative filtering recommendation system. The package supports multiple algorithms. You can find out the names of each method and the associated parameters as follows: library(recommenderlab) # Methods and default parameters in the package recommenderRegistry$get_entry_names() # IBCF stands for item-based collaborative filtering # UBCF stands for user-based collaborative filtering # SVDF stands for funk singular value decomposition (UV-decomposition-based collaborative filtering) recommenderRegistry$get_entry(&quot;UBCF&quot;,dataType=&quot;realRatingMatrix&quot;) # Make sure you understand the parameters: methods, nn, weighted and normalize # other options of methods: &quot;cosine&quot;, &quot;pearson&quot;, &quot;jaccard&quot; 1.2 Evaluate recommender systems To evaluate the recommender systems, we first need to clearly define the evaluation scheme, such as using training-test split or cross-validation, the parameters associated with training-test split (i.e. the proportion of training data) or cross-validation (i.e. the number of folds), the number of item withheld in the test set. evaluationScheme(data, method, train, k, given, goodRating) # method: split, cross-validation # train: fraction of the data set used for training # k: number of folds to run the evaluation # given: single number of items given for evaluation. Positive values implement the given-x protocol, and negative values implement the all-but-x protocol. # goodRating: threshold at which ratings are considered good for evaluation. E.g., with goodRating=3 all items with actual user rating of greater or equal 3 are considered positives in the evaluation process. After that, we can evaluate a single or a list of recommendation systems. In particular, for the task of predicting ratings, MAE (mean absolute error), MSE (mean squared error) and RMSE (root mean squared error) are calculated. For the task of predicting the top-\\(N\\) items, binary classification metrics, such as precision, recall, true positive rate (TPR), false positive rate (FPR), are returned. evaluate(evaluationScheme, method, type) # type: &quot;ratings&quot;, &quot;topNList&quot; "],["example-1-jester5k.html", "2 Example 1: Jester5k", " 2 Example 1: Jester5k This example is designed to illustrate the process of building recommender systems. The dataset we will be investigating is the Jester5k data, which contains a sample of 5000 users from the anonymous ratings data from the Jester Online Joke Recommender System collected between April 1999 and May 2003. The data set contains ratings for 100 jokes on a scale from âˆ’10 to +10. The dataset is available in the recommenderlab package: library(recommenderlab) data(Jester5k) Reference: Section 5.4 of the recommenderlab package vignette "],["exploratory-data-analysis.html", "3 Exploratory data analysis", " 3 Exploratory data analysis First, let's investigate the data a bit. Revise the R code in the lecture note and answer the following questions: How many items (i.e. jokes) are there in this dataset? On average, how many jokes do the users rate? You can report the median value in this case to get an integer value. On average, how many ratings have been made to each joke? Hint You can get information about the dataset by using the cat() function. rowCounts and colCounts can be useful to get information about items and users. ` Solution cat(JesterJokes[1]) #Joke information ## A man visits the doctor. The doctor says &quot;I have bad news for you.You have cancer and Alzheimer&#39;s disease&quot;. The man replies &quot;Well,thank God I don&#39;t have cancer!&quot; Jester5k ## 5000 x 100 rating matrix of class &#39;realRatingMatrix&#39; with 363209 ratings. Jester5k@data[1:5,1:5] ## 5 x 5 sparse Matrix of class &quot;dgCMatrix&quot; ## j1 j2 j3 j4 j5 ## u7452 -1.60 -3.54 4.17 1.84 -0.44 ## u8016 2.04 -9.42 5.53 -3.83 -8.50 ## u7162 5.53 -9.08 0.49 -4.71 -1.07 ## u8086 . . . . -0.39 ## u23653 4.47 6.80 8.20 6.89 6.55 image(Jester5k@data[1:5,1:5]) summary(rowCounts(Jester5k)) #No. jokes rated by a user ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 36.00 53.00 72.00 72.64 100.00 100.00 summary(colCounts(Jester5k)) #No. users rated a joke ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1732 2082 3971 3632 4957 5000 hist(getRatings(Jester5k), breaks=100) #getRating(): extract a vector with all non-missing ratings from a rating matrix "],["build-recommender-systems-and-make-predictions-1.html", "4 Build recommender systems and make predictions", " 4 Build recommender systems and make predictions First, let's build a user-based collaborative filtering (UBCF) system to predict the ratings and the top-\\(N\\) recommendations. Here, we use Pearson correlation to measure the similarity between users and select the nearest five users to form a neighbourhood. Jester_UBCF &lt;- Recommender(Jester5k, method=&quot;UBCF&quot;, param=list(method=&quot;pearson&quot;,nn=5)) # Predict ratings only for unrated items Jester_UBCF_rating &lt;- predict(Jester_UBCF, Jester5k, type=&quot;ratings&quot;) Jester_UBCF_rating@data[5:10,1:10] ## 6 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## ## u23653 . . . . . . . . . ## u9196 -0.07931507 -11.389315 -11.09932 -8.529315 . 1.979581 . . -11.969315 ## u623 . . . . . . . . . ## u15241 -6.58902953 -9.318072 -10.24682 -7.785684 . . . . -5.911201 ## u10885 . . . . . . . . . ## u934 . . . . . . . . . ## ## u23653 . ## u9196 2.338837 ## u623 . ## u15241 . ## u10885 . ## u934 . # Predict ratings for all items Jester_UBCF_ratMat &lt;- predict(Jester_UBCF, Jester5k, type=&quot;ratingMatrix&quot;) Jester_UBCF_ratMat@data[5:10,1:10] ## 6 x 10 sparse Matrix of class &quot;dgCMatrix&quot; ## ## u23653 4.47000000 6.500162 8.20000 6.890000 4.4607620 6.249957 ## u9196 -0.07931507 -11.389315 -11.09932 -8.529315 -0.9528821 1.979581 ## u623 2.82000000 8.443053 -3.25000 -4.900000 0.5686730 8.790000 ## u15241 -6.58902953 -9.318072 -10.24682 -7.785684 -10.9454347 -8.377496 ## u10885 7.23000000 2.140000 3.11000 0.830000 4.7309487 5.455884 ## u934 2.28000000 5.050000 3.25000 -4.030000 -2.5496590 -1.410000 ## ## u23653 5.6891707 3.2277391 -7.860000 1.682018 ## u9196 0.9858209 2.6325211 -11.969315 2.338837 ## u623 -1.3240298 -2.2544086 -2.280000 0.190000 ## u15241 -6.2988748 -6.6407474 -5.911201 -7.945736 ## u10885 -4.5946605 2.0570513 3.300000 3.365357 ## u934 -5.2687146 0.0676189 -2.620000 3.395148 # Recommend top-3 items. Jester_UBCF_topN &lt;- predict(Jester_UBCF, Jester5k, type=&quot;topNList&quot;, n=3) getList(Jester_UBCF_topN)[1:5] ## $`0` ## character(0) ## ## $`1` ## character(0) ## ## $`2` ## [1] &quot;j88&quot; &quot;j86&quot; &quot;j72&quot; ## ## $`3` ## [1] &quot;j93&quot; &quot;j76&quot; &quot;j86&quot; ## ## $`4` ## character(0) # some users have rated all items and thus the prediction returns &quot;character(0)&quot; Let's now move on to an item-based collaborative filtering (IBCF) system. Jester_IBCF &lt;- Recommender(Jester5k, method=&quot;IBCF&quot;, param=list(k=20)) #k: no. similar items You can revise the previous codes on the UBCF system to predict ratings and top-\\(N\\) items with the new IBCF system. Finally, we can perform UV-decomposition on the rating matrix. Strictly speaking, the package implements the idea of matrix factorization using singular value decomposition (SVD), which is numerically more robust and efficient. The key parameter for matrix decomposition (either UV or SVD) is the latent dimension, which is set as 3 in the following code. Jester_UV &lt;- Recommender(Jester5k,method=&quot;SVDF&quot;, param=list(k=3)) #k: latent dimension dim(Jester_UV@model$svd$U) ## [1] 5000 3 dim(Jester_UV@model$svd$V) ## [1] 100 3 "],["evaluate-recommender-systems-using-built-in-functions.html", "5 Evaluate recommender systems using built-in functions 5.1 Evaluate predicted ratings 5.2 Evaluate top-N recommendations", " 5 Evaluate recommender systems using built-in functions 5.1 Evaluate predicted ratings We evaluate the three recommendation systems using 10-fold cross-validation. For the test set, 5 items will be given to the recommender algorithm to make the prediction and the rest of items will be held out for computing the error. Below is an example on evaluating UBCF. set.seed(1) Jester_eval &lt;- evaluationScheme(Jester5k, method=&quot;cross-validation&quot;, train=10, given=5) Jester_eval UV_results &lt;- evaluate(Jester_eval, method=&quot;UBCF&quot;, type=&quot;ratings&quot;, param=list(method=&quot;pearson&quot;, nn=20)) getResults(UV_results) avg(UV_results) When evaluating multiple recommender algorithms, we can create a list of algorithms and evaluate them all together. The following R code will take a while to complete. algs &lt;- list( &quot;UBCF&quot; = list(name=&quot;UBCF&quot;, param=list(method=&quot;pearson&quot;,nn=20)), &quot;IBCF&quot; = list(name=&quot;IBCF&quot;, param=list(k=5)), &quot;UV&quot; = list(name=&quot;SVDF&quot;, param=list(k=5)) ) Jester_results &lt;- evaluate(Jester_eval, algs, type=&quot;ratings&quot;) # getResults(Jester_results$UBCF) # getResults(Jester_results$IBCF) # getResults(Jester_results$UV) avg(Jester_results) plot(Jester_results, legend=&quot;topright&quot;) 5.2 Evaluate top-N recommendations Given our data is a real rating matrix, we need to convert it into a binary matrix in order to evaluate if the top-\\(N\\) recommended items will be liked by the user. This conversion is achieved by using the argument goodRating, which is a threshold on the actual ratings; values at or above the threshold is considered to be liked by the user and vice versa. In other words, an item in the topNList is considered a true positive if it has a rating of goodRating or better in the observed data. Jester_eval2 &lt;- evaluationScheme(Jester5k, method=&quot;cross&quot;, k=5, given=-5, goodRating=0) Jester_eval2 Jester_results2 &lt;- evaluate(Jester_eval2, algs, type=&quot;topNList&quot;, n=c(1,3,5,10)) # n: the number of items in top-N list avg(Jester_results2) plot(Jester_results2, annotate=1, legend=&quot;topleft&quot;) The above example covers collaborative filtering recommender systems. If you are interested in content-based recommender systems, the following example may be studied: https://michael.hahsler.net/other_courses/ICMA_Recommendation_Tools/code/content-based.html#calculate-content-based-item-similarity "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
